 Kafka 副本机制原理

    Kafka 使用副本机制来保证数据的持久性和可用性。每个 partition 都有一个 leader 和多个 follower 副本：

     - Leader 副本: 处理所有读写请求
     - Follower 副本: 从 leader 同步数据，保持数据一致性

    不同副本因子的容错能力

    副本因子 = 1（无副本）

     1 Partition: [A]
     2 Brokers:   [B1]
     - 容错能力: 0（任何 broker 故障都会导致数据不可用）
     - 风险: 数据丢失，服务中断
     - 适用场景: 开发测试环境

    副本因子 = 2（1 个副本）

     1 Partition: [A, A']
     2 Brokers:   [B1, B2]
     - 容错能力: 1（允许 1 个 broker 故障）
     - 风险: 当一个 broker 故障后，如果另一个也故障，数据就丢失了
     - 写入性能: 较好（只需同步到 1 个副本）

    副本因子 = 3（2 个副本）

     1 Partition: [A, A', A'']
     2 Brokers:   [B1, B2, B3]
     - 容错能力: 2（允许 2 个 broker 故障）
     - 安全性: 高（即使 1 个 broker 故障，仍有 2 个副本可用）
     - 写入性能: 平衡（需要同步到 2 个副本）

    为什么生产环境推荐副本因子 3？

    1. 容错性最佳平衡
     - 允许 2 个 broker 故障，但通常我们只考虑 1 个故障场景
     - 在 1 个 broker 故障的情况下，系统仍能正常运行
     - 提供了足够的安全边际

    2. 满足 CAP 定理的 AP 要求
     - 在网络分区情况下，仍然可以继续服务（可用性）
     - 数据一致性通过 ISR（In-Sync Replicas）机制保证

    3. 实际运维考虑
     - 计划内维护: 可以滚动重启，每次停掉 1 个 broker
     - 意外故障: 单个 broker 故障不会影响服务
     - 硬件故障: 磁盘损坏、网络问题等常见故障场景

    4. 性能与成本权衡
     - 副本因子 3 提供了良好的性能（相比更高副本数）
     - 存储成本是原始数据的 3 倍，这是可接受的成本
     - 写入延迟相对较低（相比更高副本数）

    5. 行业标准
     - 大多数生产环境都采用副本因子 3
     - 这已成为事实上的标准配置

    副本因子与故障容忍度对照表


    ┌──────────┬──────────────┬──────────┬──────────┬────────────┐
    │ 副本因子 │ 可容忍故障数 │ 存储开销 │ 写入性能 │ 适用场景   │
    ├──────────┼──────────────┼──────────┼──────────┼────────────┤
    │ 1        │ 0            │ 1x       │ 最高     │ 开发/测试  │
    │ 2        │ 1            │ 2x       │ 高       │ 准生产环境 │
    │ 3        │ 2            │ 3x       │ 平衡     │ 生产环境   │
    │ 4        │ 3            │ 4x       │ 较低     │ 关键业务   │
    │ 5        │ 4            │ 5x       │ 低       │ 极关键业务 │
    └──────────┴──────────────┴──────────┴──────────┴────────────┘


    实际案例

    假设你有 6 个 brokers，副本因子为 3：
     - 每个 partition 在 3 个不同的 brokers 上有副本
     - 如果 1 个 broker 故障，该 broker 上的所有 leaders 会重新选举到其他 brokers
     - 服务继续正常运行，只是性能可能略有下降
     - 当故障 broker 恢复后，会自动同步数据并重新加入集群

    这就是为什么副本因子 3 成为生产环境推荐配置的原因——它在容错性、性能和成本之间达到了最佳平衡。

    生产者数量不应超过 broker 数量的 2 倍
    sent_div_requested_mb_per_sec = 实际发送吞吐量 / 请求的吞吐量

    为什么 2 倍是合理的选择

    1. 负载均衡优势
     - 12 个 partitions 可以均匀分布在 6 个 brokers 上（每个 broker 承载 2 个 partitions）
     - 避免了某些 broker 负载过重的情况

    2. 并行处理能力
     - 提供了足够的并行度，允许多个 consumer 实例同时消费
     - 支持最多 12 个 consumer 实例并行处理（在一个 consumer group 内）

    3. 容错性
     - 如果某个 broker 故障，其上的 partitions 会被重新分配到其他 brokers
     - 2 倍的关系提供了良好的冗余和恢复能力

    4. 管理开销平衡
     - 不会因为过多的 partitions 增加过多的管理开销
     - 每个 broker 只需管理 2 个 partitions，开销可控